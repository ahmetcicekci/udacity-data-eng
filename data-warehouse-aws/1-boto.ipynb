{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DWH Params from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>single-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>awsuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>123456Ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>redshift-role</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param             Value\n",
       "0        DWH_CLUSTER_TYPE       single-node\n",
       "1           DWH_NUM_NODES                 1\n",
       "2           DWH_NODE_TYPE         dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER  redshift-cluster\n",
       "4                  DWH_DB               dev\n",
       "5             DWH_DB_USER           awsuser\n",
       "6         DWH_DB_PASSWORD          123456Ab\n",
       "7                DWH_PORT              5439\n",
       "8       DWH_IAM_ROLE_NAME     redshift-role"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clients and resources for IAM, EC2, S3, and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2', region_name=\"us-east-1\", aws_access_key_id=KEY, aws_secret_access_key=SECRET)\n",
    "s3 = boto3.resource('s3', region_name=\"us-east-1\", aws_access_key_id=KEY, aws_secret_access_key=SECRET)\n",
    "iam = boto3.client('iam', region_name='us-east-1', aws_access_key_id=KEY, aws_secret_access_key=SECRET)\n",
    "redshift = boto3.client('redshift', region_name=\"us-east-1\", aws_access_key_id=KEY, aws_secret_access_key=SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: IAM ROLE\n",
    "- Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name redshift-role already exists.\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::472183003754:role/redshift-role\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2:  Redshift Cluster\n",
    "\n",
    "- Create a [RedShift Cluster](https://console.aws.amazon.com/redshiftv2/home)\n",
    "- For complete arguments to `create_cluster`, see [docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Describe the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>creating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>awsuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0d575ba0a4123e80c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key                  Value\n",
       "0  ClusterIdentifier       redshift-cluster\n",
       "1           NodeType              dc2.large\n",
       "2      ClusterStatus               creating\n",
       "3     MasterUsername                awsuser\n",
       "4             DBName                    dev\n",
       "5              VpcId  vpc-0d575ba0a4123e80c\n",
       "6      NumberOfNodes                      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Take note of the cluster endpoint and role ARN\n",
    "- DO NOT RUN THIS unless the cluster status becomes \"Available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  redshift-cluster.ceied2kgdafs.us-east-1.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::472183003754:role/redshift-role\n"
     ]
    }
   ],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Open an incoming TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0ddde59372e38e173')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Make sure you connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://awsuser:_~2[Bcp9|8Dx@redshift-cluster-1.ceied2kgdafs.us-east-1.redshift.amazonaws.com:5439/dev\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1967, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/default.py\", line 941, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "psycopg2.errors.UndefinedObject: unrecognized configuration parameter \"standard_conforming_strings\"\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sql/connection.py\", line 70, in set\n",
      "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sql/connection.py\", line 55, in __init__\n",
      "    self.internal_connection = engine.connect()\n",
      "                               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3278, in connect\n",
      "    return self._connection_cls(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 146, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3302, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 449, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 1263, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 712, in checkout\n",
      "    rec = pool._do_get()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 179, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    return self._create_connection()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 390, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 674, in __init__\n",
      "    self.__connect()\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 914, in __connect\n",
      "    )._exec_w_sync_on_first_run(self.dbapi_connection, self)\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/event/attr.py\", line 483, in _exec_w_sync_on_first_run\n",
      "    self(*args, **kw)\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/event/attr.py\", line 497, in __call__\n",
      "    fn(*args, **kw)\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 1912, in go\n",
      "    return once_fn(*arg, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/create.py\", line 749, in first_connect\n",
      "    dialect.initialize(c)\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\", line 677, in initialize\n",
      "    super().initialize(connection)\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/base.py\", line 3120, in initialize\n",
      "    self._set_backslash_escapes(connection)\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/base.py\", line 5004, in _set_backslash_escapes\n",
      "    std_string = connection.exec_driver_sql(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1779, in exec_driver_sql\n",
      "    ret = self._execute_context(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1846, in _execute_context\n",
      "    return self._exec_single_context(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1986, in _exec_single_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 2355, in _handle_dbapi_exception\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 1967, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/Users/ahmetcicekci/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/sqlalchemy/engine/default.py\", line 941, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedObject) unrecognized configuration parameter \"standard_conforming_strings\"\n",
      "\n",
      "[SQL: show standard_conforming_strings]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Clean up your resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'redshift-cluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'awsuser',\n",
       "  'DBName': 'dev',\n",
       "  'Endpoint': {'Address': 'redshift-cluster.ceied2kgdafs.us-east-1.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2024, 8, 18, 20, 22, 26, 751000, tzinfo=tzutc()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-0ddde59372e38e173',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-0d575ba0a4123e80c',\n",
       "  'AvailabilityZone': 'us-east-1c',\n",
       "  'PreferredMaintenanceWindow': 'thu:08:30-thu:09:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 1,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::472183003754:role/redshift-role',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2024, 8, 22, 8, 30, tzinfo=tzutc()),\n",
       "  'ClusterNamespaceArn': 'arn:aws:redshift:us-east-1:472183003754:namespace:73fb065a-606e-4f63-b7aa-5ad1ffd4bdb8',\n",
       "  'TotalStorageCapacityInMegaBytes': 400000,\n",
       "  'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "   'AquaConfigurationStatus': 'auto'},\n",
       "  'MultiAZ': 'Disabled'},\n",
       " 'ResponseMetadata': {'RequestId': '84f42ec5-47a8-4c13-b477-9254b37a1564',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '84f42ec5-47a8-4c13-b477-9254b37a1564',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2899',\n",
       "   'date': 'Sun, 18 Aug 2024 21:31:55 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift.delete_cluster(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClusterNotFoundFault",
     "evalue": "An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster redshift-cluster not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClusterNotFoundFault\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m myClusterProps \u001b[38;5;241m=\u001b[39m \u001b[43mredshift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mClusterIdentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDWH_CLUSTER_IDENTIFIER\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClusters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m prettyRedshiftProps(myClusterProps)\n",
      "File \u001b[0;32m~/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/udacity-data-eng/data-warehouse-aws/env-warehouse-aws/lib/python3.12/site-packages/botocore/client.py:1017\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClusterNotFoundFault\u001b[0m: An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster redshift-cluster not found."
     ]
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-warehouse-aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
